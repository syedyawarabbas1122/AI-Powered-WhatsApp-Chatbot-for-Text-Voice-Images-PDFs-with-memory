<img width="347" alt="image" src="https://github.com/user-attachments/assets/de094ce5-743c-4abf-82eb-81f043e80777" />

This workflow is a highly advanced multimodal AI assistant designed to operate through WhatsApp. It can understand and respond to text, images, voice messages, and PDF documents by combining OpenAI models with smart logic to adapt to the content received.
________________________________________
üéØ Core Features
üì• 1. Automatic Message Type Detection
Using the Input type node, the bot detects whether the user has sent:
‚Ä¢	Text
‚Ä¢	Voice messages
‚Ä¢	Images
‚Ä¢	Files (PDF)
‚Ä¢	Other unsupported content
üí¨ 2. Smart Text Message Handling
‚Ä¢	Text messages are processed by an OpenAI GPT-4o-mini agent with a customized system prompt.
‚Ä¢	Replies are concise, accurate, and formatted for mobile readability.
üñºÔ∏è 3. Image Analysis & Description
‚Ä¢	Images are downloaded, converted to base64, and analyzed by an image-aware AI model.
‚Ä¢	The output is a rich, structured description, designed for visually impaired users or visual content interpretation.
üéôÔ∏è 4. Voice Message Transcription & Reply
‚Ä¢	Audio messages are downloaded and transcribed using OpenAI Whisper.
‚Ä¢	The transcribed text is analyzed and answered by the AI.
‚Ä¢	Optionally, the AI reply can be converted back to voice using OpenAI's text-to-speech, and sent as an audio message.
üìÑ 5. PDF Document Extraction & Summary
‚Ä¢	Only PDFs are allowed (filtered via MIME type).
‚Ä¢	The document‚Äôs content is extracted and combined with the user's message.
‚Ä¢	The AI then provides a relevant summary or answer.
üß† 6. Contextual Memory
‚Ä¢	Each user has a personalized session ID with a memory window of 10 interactions.
‚Ä¢	This ensures a more natural and contextual conversation flow.
________________________________________
How It Works
Thisworkflow is designed to handle incoming WhatsApp messages and process different types of inputs (text, audio, images, and PDF documents) using AI-powered analysis. Here‚Äôs how it functions:
‚Ä¢	Trigger: The workflow starts with the WhatsApp Trigger node, which listens for incoming messages (text, audio, images, or documents).
‚Ä¢	Input Routing: The Input type (Switch node) checks the message type and routes it to the appropriate processing branch:
‚Ä¢	Text: Directly forwards the message to the AI agent for response generation.
‚Ä¢	Audio: Downloads the audio file, transcribes it using OpenAI, and sends the transcription to the AI agent.
‚Ä¢	Image: Downloads the image, analyzes it with OpenAI‚Äôs GPT-4 model, and generates a detailed description.
‚Ä¢	PDF Document: Downloads the file, extracts text, and processes it with the AI agent.
‚Ä¢	Unsupported Formats: Sends an error message if the input is not supported.
‚Ä¢	AI Processing: The AI Agent1 node, powered by OpenAI, processes the input (text, transcribed audio, image description, or PDF content) and generates a response.
‚Ä¢	Response Handling:
‚Ä¢	For audio inputs, the AI‚Äôs response is converted back into speech (using OpenAI‚Äôs TTS) and sent as a voice message.
‚Ä¢	For other inputs, the response is sent as a text message via WhatsApp.
‚Ä¢	Memory: The Simple Memory node maintains conversation context for follow-up interactions.
Setup Steps
To deploy this workflow in n8n, follow these steps:
1.	Configure WhatsApp API Credentials:
‚Ä¢	Set up WhatsApp Business API credentials (Meta Developer Account).
‚Ä¢	Add the credentials in the WhatsApp Trigger, Get Image/Audio/File URL, and Send Message nodes.
Set Up OpenAI Integration:
‚Ä¢	Provide an OpenAI API key in the Analyze Image, Transcribe Audio, Generate Audio Response, and AI Agent1 nodes.
Adjust Input Handling (Optional):
‚Ä¢	Modify the Switch node ("Input type") to handle additional message types if needed.
‚Ä¢	Update the "Only PDF File" IF node to support other document formats.
Test & Deploy:
‚Ä¢	Activate the workflow and test with different message types (text, audio, image, PDF).
‚Ä¢	Ensure responses are correctly generated and sent back via WhatsApp.

